Base code from https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning/, modified in order to be able to detect multiple hands and trained off of a small dataset of 3 gestures.
Modified final.py to create a prototype of a quiz functionality that triggers for full sign language motions instead of just static gestures.

Actual build already inside the folder, along with all training datasets used:
0 - Again
1 - Again (follow through)
2 - Yes 
3 - Yes (follow through)
4 - No
5 - No (follow through)
